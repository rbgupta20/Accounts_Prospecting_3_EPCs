# ==========================================
# STEP 1: Install dependencies
# ==========================================
!pip install google-search-results pandas tqdm

# ==========================================
# STEP 2: Import libraries
# ==========================================
from serpapi import GoogleSearch
import pandas as pd
import time
from tqdm import tqdm
import getpass

# ==========================================
# STEP 3: Ask for SerpAPI key securely
# ==========================================
SERP_API_KEY = getpass.getpass("üîë Enter your SerpAPI Key: ")

if not SERP_API_KEY.strip():
    raise ValueError("‚ùå SerpAPI key cannot be empty")

# ==========================================
# STEP 4: Search queries
# ==========================================
queries = [
    "Infrastructure companies in Lucknow",
    "Infrastructure companies in Kanpur",
    "Infrastructure companies in Agra",
    "Infrastructure companies in Prayagraj",
    "Infrastructure companies in Allahabad",
    "Infrastructure companies in Jhansi"
]

# ==========================================
# STEP 5: Google search function (MAX 30 results)
# ==========================================
def get_google_search_results(query, num_results=30):
    all_results = []
    results_per_page = 10

    for start in range(0, num_results, results_per_page):
        params = {
            "engine": "google",
            "q": f"{query} -indiamart -justdial",
            "api_key": SERP_API_KEY,
            "num": results_per_page,
            "start": start,
            "gl": "in",
            "hl": "en"
        }

        try:
            search = GoogleSearch(params)
            data = search.get_dict()

            if "organic_results" in data:
                all_results.extend(data["organic_results"])

        except Exception as e:
            print(f"‚ùå Error for query '{query}': {e}")

        time.sleep(1.5)

    return all_results

# ==========================================
# STEP 6: Collect & deduplicate results
# ==========================================
all_data = []
seen_links = set()

for query in tqdm(queries, desc="Searching"):
    results = get_google_search_results(query, num_results=30)

    for res in results:
        link = res.get("link", "").strip()
        if not link or link in seen_links:
            continue

        seen_links.add(link)

        all_data.append({
            "search_query": query,
            "google_position": res.get("position", ""),
            "title": res.get("title", ""),
            "website": link,
            "snippet": res.get("snippet", ""),
            "displayed_link": res.get("displayed_link", "")
        })

# ==========================================
# STEP 7: Save CSV
# ==========================================
df = pd.DataFrame(all_data)
output_file = "infrastructure_companies_uttar_pradesh.csv"
df.to_csv(output_file, index=False)

print(f"‚úÖ CSV saved as '{output_file}' with {len(df)} unique websites")
df.head()
